import socket
import os
import struct
import time
import torch
import numpy as np
import cv2
import argparse
import json
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# 0.0.0.0 -> all interfaces

class SmolVLAInferenceServer:
    def __init__(self, ckpt_path, host='0.0.0.0', port=5001, device='cuda', eval_freq=None, task=""):
        self.eval_freq = eval_freq  # Hz
        self.eval_interval = 1.0 / eval_freq if eval_freq and eval_freq > 0 else 0.0

        # Prompt
        self.task = task

        # Device
        self.device = device
        if device == 'cuda' and not torch.cuda.is_available():
            print("âš ï¸ CUDA ä¸å¯ç”¨ï¼Œè‡ªå‹•åˆ‡æ›ç‚º CPU")
            self.device = 'cpu'
        print("Using:", self.device)

        # Model
        ckpt_path = os.path.abspath(ckpt_path)
        print(f"ğŸ“‚ ä½¿ç”¨çš„ ckpt_path: {ckpt_path}")
        self.policy = SmolVLAPolicy.from_pretrained(ckpt_path, local_files_only=True)
        self.policy.to(self.device)
        self.policy.eval()

        # å°å¹…åº¦åŠ é€Ÿï¼ˆå½±åƒå°ºå¯¸å›ºå®šæ™‚æœ‰æ•ˆï¼‰
        try:
            torch.backends.cudnn.benchmark = True
        except Exception:
            pass

        # Server socket
        self.server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        # å»ºè­°æ‰“é–‹é‡ç”¨ä½å€èˆ‡è¼ƒå¤§çš„ backlogï¼ˆè¦–éœ€è¦ï¼‰
        self.server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server_socket.bind((host, port))
        self.server_socket.listen(8)
        print(" SmolVLA æ¨è«–ä¼ºæœå™¨å·²å•Ÿå‹•ï¼Œç­‰å¾… client é€£ç·š...")

        # åˆæ¬¡ accept
        self._accept_client()

    # ---- socket helpers ----
    def _apply_conn_opts(self, sock):
        # åœ¨é€£ç·š socket è¨­ TCP_NODELAY èˆ‡è¼ƒå¤§ buffer
        sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 4*1024*1024)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 4*1024*1024)
        # ï¼ˆå¯é¸ï¼‰keepalive
        try:
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
        except Exception:
            pass

    def _accept_client(self):
        self.conn, self.addr = self.server_socket.accept()
        self._apply_conn_opts(self.conn)
        print(" client å·²é€£ç·š:", self.addr)

    def recv_exact(self, n):
        buf = b''
        while len(buf) < n:
            chunk = self.conn.recv(n - len(buf))
            if not chunk:
                return None
            buf += chunk
        return buf

    def recv_one_message(self):
        t0 = time.time()
        raw_len = self.recv_exact(4)
        if raw_len is None:
            return None, None, 0, 0.0
        data_len = struct.unpack('>I', raw_len)[0]

        raw_type = self.recv_exact(10)
        if raw_type is None:
            return None, None, 0, 0.0
        try:
            data_type = raw_type.decode('utf-8').strip()
        except UnicodeDecodeError:
            raise RuntimeError("Framing desync: invalid type header")

        data = self.recv_exact(data_len)
        if data is None:
            return None, None, 0, 0.0

        return data_type, data, data_len, (time.time() - t0)

    def _decode_image(self, data_bytes, name):
        arr = np.frombuffer(data_bytes, np.uint8)
        img = cv2.imdecode(arr, cv2.IMREAD_COLOR)
        if img is None:
            raise RuntimeError(f"Failed to decode {name}")
        return img

    def send_data(self, data_type, data_bytes):
        hdr_type = data_type.ljust(10).encode('utf-8')
        data_len = struct.pack('>I', len(data_bytes))
        self.conn.sendall(data_len + hdr_type + data_bytes)

    # ---- main loop ----
    def run(self):
        last_time = time.time()
        while True:
            try:

                # FIXED FREQUENCY CONTROLLER
                if self.eval_interval > 0:
                    if not hasattr(self, "next_tick"):
                        self.next_tick = time.time()

                    now = time.time()
                    if now < self.next_tick:
                        time.sleep(self.next_tick - now)

                    self.next_tick += self.eval_interval
                # END FIXED FREQUENCY CONTROLLER

                loop_t0 = time.time()
                proc_t0 = loop_t0

                # 1) state
                t, d, s1, dt1 = self.recv_one_message()
                if t != 'list':
                    raise RuntimeError(f"Unexpected type for state: {t}")
                try:
                    state = json.loads(d.decode('utf-8'))
                except Exception as e:
                    raise RuntimeError(f"State JSON decode failed: {e}")
                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(self.device, non_blocking=True)

                # 2) img1
                t, d, s2, dt2 = self.recv_one_message()
                if t != 'img1':
                    raise RuntimeError(f"Unexpected type for img1: {t}")
                img1 = self._decode_image(d, "img1")
 
                # 3) img2
                t, d, s3, dt3 = self.recv_one_message()
                if t != 'img2':
                    raise RuntimeError(f"Unexpected type for img2: {t}")
                img2 = self._decode_image(d, "img2")

                # 4) img3
                t, d, s4, dt4 = self.recv_one_message()
                if t != 'img3':
                    raise RuntimeError(f"Unexpected type for img3: {t}")
                img3 = self._decode_image(d, "img3")

                # build obsï¼ˆéåŒæ­¥æ‹·è²ï¼›å¾ŒçºŒå¯è€ƒæ…® AMP/halfï¼‰
                obs = {
                    'observation.state': state_tensor,
                    'observation.images.image_front_eye':
                        torch.from_numpy(img1).permute(2,0,1).unsqueeze(0).float().to(self.device, non_blocking=True)/255.0,
                    'observation.images.image_rear_eye':
                        torch.from_numpy(img2).permute(2,0,1).float().unsqueeze(0).to(self.device, non_blocking=True)/255.0,
                    'observation.images.image_front_view':
                        torch.from_numpy(img3).permute(2,0,1).float().unsqueeze(0).to(self.device, non_blocking=True)/255.0,
                    'task': [self.task],
                }

                # inference
                # --- NEW: chunk inference ---
                inf_t0 = time.time()
                with torch.no_grad():
                    if self.device == 'cuda':
                        with torch.cuda.amp.autocast():
                            actions = self.policy.predict_action_chunk(obs)
                    else:
                        actions = self.policy.predict_action_chunk(obs)
                inf_t1 = time.time()

                # actions: [1, H, action_dim] -> [H, action_dim] -> Python list
                action_chunk = actions.squeeze(0).detach().cpu().numpy().tolist()

                # Optionally keep only the first n_action_steps, if defined in config
                n_steps = getattr(self.policy.config, "n_action_steps", None)
                if n_steps is not None and len(action_chunk) > n_steps:
                    action_chunk = action_chunk[:n_steps]

                # For logging, just look at the first actionâ€™s gripper (index 7)
                first_gripper = action_chunk[0][7] if len(action_chunk) and len(action_chunk[0]) > 7 else None

                now = time.time()
                total_interval = now - last_time
                last_time = now
                total_freq = 1.0 / total_interval if total_interval > 0 else 0.0
                infer_freq = 1.0 / (inf_t1 - inf_t0) if inf_t1 > inf_t0 else 0.0
                proc_interval = inf_t0 - proc_t0
                total_bytes = s1 + s2 + s3 + s4
                total_xfer_time = dt1 + dt2 + dt3 + dt4
                xfer_mbps = (total_bytes / total_xfer_time) / (1024 * 1024) if total_xfer_time > 0 else 0.0

                print(
                    f"æ¨è«–å®Œæˆ (chunk size {len(action_chunk)}): "
                    f"{np.round(first_gripper, 6) if first_gripper is not None else 'N/A'} | "
                    f"ç¸½é »ç‡: {total_freq:.2f} Hz | ç´”æ¨è«–é »ç‡: {infer_freq:.2f} Hz | "
                    f"è³‡æ–™è™•ç†è€—æ™‚: {proc_interval:.4f} s | å‚³è¼¸é€Ÿç‡: {xfer_mbps:.2f} MB/s"
                )

                # Send the whole chunk: [[...], [...], ...]
                self.send_data('list', json.dumps(action_chunk).encode('utf-8'))


                # optional throttle
                if self.eval_interval > 0.0:
                    elapsed = time.time() - loop_t0
                    sleep_time = self.eval_interval - elapsed
                    if sleep_time > 0:
                        time.sleep(sleep_time)

            except Exception as e:
                print("âŒ é€£ç·š/å°åŒ…éŒ¯èª¤ï¼Œé—œé–‰é€£ç·šç­‰å¾…é‡é€£ï¼š", e)
                try:
                    self.conn.close()
                except Exception:
                    pass
                self._accept_client()
                last_time = time.time()
                continue

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--ckpt-path', type=str, required=True)
    parser.add_argument('--host', type=str, default='0.0.0.0')
    parser.add_argument('--port', type=int, default=5001)
    parser.add_argument('--device', type=str, default='cuda')
    parser.add_argument('--eval-freq', type=float, default=0.0)  # 0 = ä¸ç¯€æµï¼Œè¿½æ±‚æœ€é«˜é »ç‡
    parser.add_argument('--task', type=str, default="pick up the red cube and place it",
                    help="Language task/instruction for SmolVLA")
    args = parser.parse_args()

    server = SmolVLAInferenceServer(
        ckpt_path=args.ckpt_path,
        host=args.host,
        port=args.port,
        device=args.device,
        eval_freq=args.eval_freq,
        task=args.task,
    )
    server.run()
